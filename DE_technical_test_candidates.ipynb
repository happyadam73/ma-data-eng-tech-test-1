{"cells":[{"metadata":{},"id":"83523bbf","cell_type":"markdown","source":"# Data Engineering Technical test\n\nWelcome to the techical test for Data Engineering. The setup of the test attempts to give guide rails for completing the exercise whilst leaving some appropriate room to demonstrate your POV on best practice and problem solving. If you wish to use other python libraries, than that is fine."},{"metadata":{},"id":"3d1b14c2","cell_type":"markdown","source":"## Introduction\nFor this technical test, we are going to use open source airbnb data for amsterdam available at the following URL:\nhttp://insideairbnb.com/get-the-data.html\n\nOver 3 parts, the test is intended to 'simulate' a brief end to end data engineering exercise, where we will test your data wrangling skills in both Python and SQL, to demonstrate your capability in those technologies. As the test is mean't simulate a real task, clearly you may utilise resources across the web to help you solve these tasks as you would day to day. \n\nSome that you may want to reference are below:\n\nhttps://pandas.pydata.org/docs/\n\nhttps://www.sqlite.org/lang.html"},{"metadata":{},"id":"fd15cae9","cell_type":"markdown","source":"## Part 1: Python - Reading and exploring raw datasets\nIn this section of the test we will be assessing your python skills. You should provide your coded, executable answers between the markers `#** Write your code here **#`"},{"metadata":{"trusted":true},"id":"f7e5b74c","cell_type":"code","source":"# Perform your python imports here\nimport pandas as pd\nimport sqlite3 as sql","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"6eea2263","cell_type":"code","source":"# Use python or bash to download, unzip and read files from the following locations\n# http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/listings.csv.gz\n# http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/calendar.csv.gz\n# http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/reviews.csv.gz\n\n# There are a number of ways of doing this, so only constraint is user is to end up with 3 datastructures \n# (we would recommend dataframes) that contain data from the three source files.\n\n#** Write your code here **#\n\ndf_calendar = pd.read_csv(\"http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/calendar.csv.gz\")\ndf_listings = pd.read_csv(\"http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/listings.csv.gz\")\ndf_reviews = pd.read_csv(\"http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-04-09/data/reviews.csv.gz\")\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{},"id":"5bc2dcff","cell_type":"markdown","source":"# Assessing and exploring the data\nNext we will perform a few common tasks on the data whilst it's still in python memory. Let's focus on the listings data in `df_listings`.\n\nAssess the following:\n- list metadata about the columns; their names and types.\n- generate a pandas style summary for the dataset.\n- count the number of rows in the dataframe.\n- find the number of missing values across the dataframe (NaN in numeric arrays, None or NaN in object arrays, NaT in datetime ).\n- assess which columns contain the missing values.\n- show the unique values in the column\n\n***The jupyter truncation of large answers is fine and candidates are not expected to set config to show every entry in answer. We are more interested in your approach than answer.***"},{"metadata":{"trusted":true},"id":"bb006f12","cell_type":"code","source":"# list metadata about the columns; their names and types.\n#** Write your code here **#\ndf_listings.info()\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"32700f7e","cell_type":"code","source":"# generate a summary for the dataset.\n#** Write your code here **#\ndf_listings.describe()\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"e4615e2c","cell_type":"code","source":"# count the number of rows in the dataframe.\n#** Write your code here **#\n\nlen(df_listings)\n\n# or df_listings.shape[0]\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"eb2dffca","cell_type":"code","source":"# find the total number of missing values across the dataframe.\n#** Write your code here **#\ndf_listings.isnull().sum().sum()\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"d72ad09b","cell_type":"code","source":"# assess which columns contain the missing values.\n#** Write your code here **#\nlist(df_listings.columns[df_listings.isnull().any()])\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"5484f6d7","cell_type":"code","source":"# show the unique values in the column host_name\n#** Write your code here **#\nlist(df_listings[\"host_name\"].unique())\n\n#** Write your code here **#\n# repeat this command two cells below","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"23fc15ca","cell_type":"code","source":"# change all instances of the name Daniel for Danny and Alexander for Alex in the column host_name\n#** Write your code here **#\ndf_listings[\"host_name\"] = df_listings[\"host_name\"].str.replace(\"Daniel\",\"Danny\", regex=False).str.replace(\"Alexander\",\"Alex\", regex=False)\n\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"id":"b4b9fc5f","cell_type":"code","source":"# Now repeat the command you used two cells above this to show the change has taken place in column host_name.\n#** Write your code here **#\nlist(df_listings[\"host_name\"].unique())\n\n#** Write your code here **#","execution_count":null,"outputs":[]},{"metadata":{},"id":"9ee407b0","cell_type":"markdown","source":"# Part 2. File formats\nIn this section we briefly assess your understanding of modern data formats."},{"metadata":{"trusted":true},"id":"4ff437c8","cell_type":"code","source":"# convert df_calendar data to parquet file named df_calendar.parquet \n#** Write your code here **#\ndf_calendar.to_parquet('df_calendar.parquet')\n\n#** Write your code here **#\n# Let's compare sizes of original csv and the parquet file.\ndf_calendar.to_csv('df_calendar.csv')\n!ls -lh *calendar*","execution_count":null,"outputs":[]},{"metadata":{},"id":"5397a112","cell_type":"markdown","source":"Briefly explain why there is likely a difference between the sizes of CSV and parquet in the box below."},{"metadata":{"trusted":false},"cell_type":"markdown","source":"### Why is the Parquet file Smaller?\n\nParquet is a columnar format which also uses compression.  Given that similar values tend to reside within a column rather than across a row, then dictionary type compression algorithms (such as GZip) work well against a columnar format like Parquet and produce significant reductions in file size.\n"},{"metadata":{},"id":"2938c616","cell_type":"markdown","source":"# Part 3. Ingesting data into a database\nIn this section of the test we are going to explore your SQL skills."},{"metadata":{"trusted":true},"id":"e647892d","cell_type":"code","source":"# first lets release memory from the previous python work and unzip and load our preprepared SQL lite database\ntry:\n    del(df_calendar)\n    del(df_listings)\n    del(df_reviews)\nexcept NameError: pass\n\n!gunzip opensource_airbnb.db.gz\nconn = sql.connect('opensource_airbnb.db')","execution_count":null,"outputs":[]},{"metadata":{},"id":"4f54786e","cell_type":"markdown","source":"We will use the Jupyter SQL magic to enable you to write vanilla SQL with little python wrap. https://github.com/catherinedevlin/ipython-sql. There is an example below."},{"metadata":{"trusted":true},"id":"a91c11ea","cell_type":"code","source":"# first load the sql magic extension.\n%load_ext sql","execution_count":null,"outputs":[]},{"metadata":{},"id":"b64486bd","cell_type":"markdown","source":"Below we show a simple example of multiline sql with sql magic, where the first line connects to the database you've loaded data into and runs a basic query"},{"metadata":{"trusted":true},"id":"198feb9c","cell_type":"code","source":"%%sql sqlite:///opensource_airbnb.db\n    SELECT DISTINCT UPPER(property_type) as property_type \n    FROM listings \n    limit 5","execution_count":null,"outputs":[]},{"metadata":{},"id":"709fb605","cell_type":"markdown","source":"## Exercises \nNow we would like you to write SQL to solve the two following problems"},{"metadata":{},"id":"d9ce92ab","cell_type":"markdown","source":"**Problem 1** \n\nOutput the Top 15 listings that accomodates 5-8 people and has the property type 'Boat', ordered by review_scores_cleanliness and has bucketed prices from '\\\\$0 - \\\\$100', '\\\\$100 - \\\\$200', '\\\\$200 - \\\\$300', '\\\\$300 - \\\\$400', '\\\\$400 - \\\\$500', '\\\\$500+'. Your result should include `id`, `listing_url`, `review_scores_cleanliness` and your `bucketed_price`. Use the `price` column for bucketing and use the following snippet to enable you to treat this column a numerical should you wish - `CAST(substr(price, 2) as REAL) as price_for_bucketing`."},{"metadata":{"trusted":true},"id":"300c935b","cell_type":"code","source":"%%sql sqlite:///opensource_airbnb.db\n\n/*\n\n(1) Note that this query currently doesn't return 15 listings since there are only 12 listings \n    which are boats that accommodate 5-8 people\n(2) If more than 15 listings existed, this query could return more than 15 rows since ties are included\n    in the RANK() function.  At an extreme, if they all had the same cleanliness score then RANK() would \n    equal one for all records and they would all be returned.\n    \n*/\n\nWITH RankedFilteredData AS (\n    SELECT\n        id,\n        listing_url,\n        review_scores_cleanliness,\n        RANK() OVER (ORDER BY review_scores_cleanliness DESC) AS cleanliness_ranking,\n        CAST(substr(price, 2) as REAL) as price_for_bucketing\n    FROM listings\n    WHERE \n        accommodates BETWEEN 5 AND 8\n    AND property_type = 'Boat'\n)\nSELECT\n    id,\n    listing_url,\n    review_scores_cleanliness,\n    CASE\n        WHEN price_for_bucketing >=0   AND price_for_bucketing < 100 THEN '$0 - $100'\n        WHEN price_for_bucketing >=100 AND price_for_bucketing < 200 THEN '$100 - $200'\n        WHEN price_for_bucketing >=200 AND price_for_bucketing < 300 THEN '$200 - $300'\n        WHEN price_for_bucketing >=300 AND price_for_bucketing < 400 THEN '$300 - $400'\n        WHEN price_for_bucketing >=400 AND price_for_bucketing < 500 THEN '$400 - $500'\n        WHEN price_for_bucketing >=500 THEN '$500+'\n        ELSE 'Invalid Price'\n    END AS bucketed_price\nFROM RankedFilteredData\nWHERE\n    cleanliness_ranking <= 15\n    ","execution_count":null,"outputs":[]},{"metadata":{},"id":"4eda2434","cell_type":"markdown","source":"**Problem 2** \n\nFind the `listing_id`, `host_name` as well as earliest available `date` and `price` of that date for the most reviewed listing in the data. That is the listing that has received the most reviews. It should return only one row."},{"metadata":{"trusted":true},"id":"b29b65a2","cell_type":"code","source":"%%sql sqlite:///opensource_airbnb.db\n\nWITH listings_and_review_counts AS (\n    SELECT\n        l.id AS listing_id,\n        l.host_name,\n        COUNT(r.id) AS review_count\n    FROM \n        listings l\n        INNER JOIN reviews r\n            ON l.id = r.listing_id\n    GROUP BY\n        l.id,\n        l.host_name\n), listings_and_ranked_review_counts AS (\n    SELECT\n        listing_id,\n        host_name,\n        review_count,\n        RANK() OVER (ORDER BY review_count DESC) AS review_count_rank\n    FROM \n        listings_and_review_counts   \n), best_viewed_listing AS (\n    SELECT\n        listing_id,\n        host_name,\n        review_count\n    FROM \n        listings_and_ranked_review_counts\n    WHERE review_count_rank = 1\n), best_viewed_listing_with_earliest_date AS (\n    SELECT\n        l.listing_id,\n        l.host_name,\n        MIN(c.date) AS earliest_date\n    FROM \n        best_viewed_listing l\n        INNER JOIN calendar c\n            ON l.listing_id = c.listing_id\n    GROUP BY\n        l.listing_id,\n        l.host_name\n)\nSELECT\n    b.listing_id,\n    b.host_name,\n    b.earliest_date,\n    c.price\nFROM\n    best_viewed_listing_with_earliest_date b\n    INNER JOIN calendar c\n        ON b.earliest_date = c.date AND\n           b.listing_id = c.listing_id\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}